@article{10.1145/3578555,
author = {Mishra, Rahul and Ramesh, Dharavath and Kanhere, Salil S. and Edla, Damodar Reddy},
title = {Enabling Efficient Deduplication and Secure Decentralized Public Auditing for Cloud Storage: A Redactable Blockchain Approach},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {2158-656X},
url = {https://doi.org/10.1145/3578555},
doi = {10.1145/3578555},
abstract = {Public auditing and data deduplication are integral considerations in providing efficient and secure cloud storage services. Nevertheless, the traditional data deduplication models that support public auditing can endure the enormous waste of storage and computation resources induced through data redundancy and repeated audit work by multiple tenants on trusted third-party auditor (TPA). In this work, we introduce blockchain-based secure decentralized public auditing in a decentralized cloud storage with an efficient deduplication model. We employ blockchain to take on the task of centralized TPA, which also mitigates the implications of malicious blockchain miners by using the concept of a decentralized autonomous organization (DAO). Specifically, we employ the idea of redactability for blockchain to handle often neglected security issues that would adversely affect the integrity of stored auditing records on blockchain in decentralized auditing models. However, the proposed model also employs an efficient deduplication scheme to attain adequate storage savings while preserving the users from data loss due to duplicate faking attacks. Moreover, the detailed concrete security analysis demonstrates the computational infeasibility of the proposed model against proof-of-ownership, duplicate faking attack (DFA), collusion attack, storage free-riding attack, data privacy, and forgery attack with high efficiency. Finally, the comprehensive performance analysis shows the scalability and feasibility of the proposed model.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = {jun},
articleno = {21},
numpages = {35},
keywords = {Public auditability, redactable blockchain, decentralized cloud storage (IPFS), data deduplication}
}

@inproceedings{10.1145/3372278.3391934,
author = {Tran, Van-Luon and Mai-Nguyen, Anh-Vu and Phan, Trong-Dat and Vo, Anh-Khoa and Dao, Minh-Son and Zettsu, Koji},
title = {An Interactive Multimodal Retrieval System for Memory Assistant and Life Organized Support},
year = {2020},
isbn = {9781450370875},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372278.3391934},
doi = {10.1145/3372278.3391934},
abstract = {Lifelogging is known as the new trend of writing diary digitally where both the surrounding environment and personal physiological data and cognition are collected at the same time under the first perspective. Exploring and exploiting these lifelog (i.e., data created by lifelogging) can provide useful insights for human beings, including healthcare, work, entertainment, and family, to name a few. Unfortunately, having a valuable tool working on lifelog to discover these insights is still a tough challenge. To meet this requirement, we introduce an interactive multimodal retrieval system that aims to provide people with two functions, memory assistant and life organized support, with a friendly and easy-to-use web UI. The output of the former function is a video with footages expressing all instances of events people want to recall. The latter function generates a statistical report of each event so that people can have more information to balance their lifestyle. The system relies on two major algorithms that try to match keywords/phrases to images and to run a cluster-based query using a watershed-based approach.},
booktitle = {Proceedings of the 2020 International Conference on Multimedia Retrieval},
pages = {416–420},
numpages = {5},
keywords = {clustering, content and context, feature extracting, image, lifelogs, retrieval, semantic},
location = {Dublin, Ireland},
series = {ICMR '20}
}

@proceedings{10.1145/3640771,
title = {ISCAI '23: Proceedings of the 2023 2nd International Symposium on Computing and Artificial Intelligence},
year = {2023},
isbn = {9798400708954},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shanghai, China}
}

@article{10.1145/3409384,
author = {Ahmadi, Naser and Truong, Thi-Thuy-Duyen and Dao, Le-Hong-Mai and Ortona, Stefano and Papotti, Paolo},
title = {RuleHub: A Public Corpus of Rules for Knowledge Graphs},
year = {2020},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {1936-1955},
url = {https://doi.org/10.1145/3409384},
doi = {10.1145/3409384},
abstract = {Entity-centric knowledge graphs (KGs) are now popular to collect facts about entities. KGs have rich schemas with a large number of different types and predicates to describe the entities and their relationships. On these rich schemas, logical rules are used to represent dependencies between the data elements. While rules are useful in query answering, data curation, and other tasks, they usually do not come with the KGs. Such rules have to be manually defined or discovered with the help of rule mining methods. We believe this rule-collection task should be done collectively to better capitalize our understanding of the data and to avoid redundant work conducted on the same KGs. For this reason, we introduce RuleHub, our extensible corpus of rules for public KGs. RuleHub provides functionalities for the archival and the retrieval of rules to all users, with an extensible architecture that does not constrain the KG or the type of rules supported. We are populating the corpus with thousands of rules from the most popular KGs and report on our experiments on automatically characterizing the quality of a rule with statistical measures.},
journal = {J. Data and Information Quality},
month = {oct},
articleno = {21},
numpages = {22},
keywords = {Rule mining, graph dependencies, knowledge graphs}
}

@proceedings{10.1145/3663338,
title = {ApPLIED'24: Proceedings of the 2024 Workshop on Advanced Tools, Programming Languages, and PLatforms for Implementing and Evaluating algorithms for Distributed systems},
year = {2024},
isbn = {9798400706707},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ApPLIED aims to bring together distributed system designers and practitioners from academia and industry to share their experiences and perspectives in designing and building distributed systems.},
location = {Nantes, France}
}

@proceedings{10.1145/3643488,
title = {ICDAR '24: Proceedings of the 5th ACM Workshop on Intelligent Cross-Data Analysis and Retrieval},
year = {2024},
isbn = {9798400705496},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Phuket, Thailand}
}

@inproceedings{10.1145/3593013.3593981,
author = {Solaiman, Irene},
title = {The Gradient of Generative AI Release: Methods and Considerations},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3593981},
doi = {10.1145/3593013.3593981},
abstract = {As increasingly powerful generative AI systems are developed, the release method greatly varies. We propose a framework to assess six levels of access to generative AI systems: fully closed; gradual or staged access; hosted access; cloud-based or API access; downloadable access; and fully open. Each level, from fully closed to fully open, can be viewed as an option along a gradient. We outline key considerations across this gradient: release methods come with tradeoffs, especially around the tension between concentrating power and mitigating risks. Diverse and multidisciplinary perspectives are needed to examine and mitigate risk in generative AI systems from conception to deployment. We show trends in generative system release over time, noting closedness among large companies for powerful systems and openness among organizations founded on principles of openness. We also enumerate safety controls and guardrails for generative systems and necessary investments to improve future releases.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {111–122},
numpages = {12},
location = {Chicago, IL, USA},
series = {FAccT '23}
}

@inproceedings{10.1145/1378063.1378151,
author = {Liu, Ying and Wang, Qiqun},
title = {Chinese pinyin phrasal input on mobile phone: usability and developing trends},
year = {2007},
isbn = {9781595938190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378063.1378151},
doi = {10.1145/1378063.1378151},
abstract = {Phrasal input is a Chinese text entry feature and just available on mobile phone lately. In the study, we compared usability of five Chinese pinyin phrasal input methods (Cstar, Guobi, Nokia, T9 and Zi) on mobile phones that represent two types: methods derived from PC pinyin phrasal input and methods derived from pinyin character input on mobile phones. The result showed that Cstar and Nokia performed the best followed by Guobi, T9, and Zi in order. We discussed the reasons behind and provided four design guidelines: 1) Find a balance between radical designs and well-accepted designs; 2) Optimize the corpus constantly; 3) Provide easy-to-use on-line phrase creation; and 4) Design a phrasal input method excluding pinyin selection process as PC pinyin phrasal input methods do.},
booktitle = {Proceedings of the 4th International Conference on Mobile Technology, Applications, and Systems and the 1st International Symposium on Computer Human Interaction in Mobile Technology},
pages = {540–546},
numpages = {7},
keywords = {Chinese, keystrokes per character, phone, pinyin, usability},
location = {Singapore},
series = {Mobility '07}
}

@article{10.1145/3593293,
author = {Ivanov, Nikolay and Li, Chenning and Yan, Qiben and Sun, Zhiyuan and Cao, Zhichao and Luo, Xiapu},
title = {Security Threat Mitigation for Smart Contracts: A Comprehensive Survey},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {14s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3593293},
doi = {10.1145/3593293},
abstract = {The blockchain technology, initially created for cryptocurrency, has been re-purposed for recording state transitions of smart contracts—decentralized applications that can be invoked through external transactions. Smart contracts gained popularity and accrued hundreds of billions of dollars in market capitalization in recent years. Unfortunately, like all other computer programs, smart contracts are prone to security vulnerabilities that have incurred multibillion-dollar damages over the past decade. As a result, many automated threat mitigation solutions have been proposed to counter the security issues of smart contracts. These threat mitigation solutions include various tools and methods that are challenging to compare. This survey develops a comprehensive classification taxonomy of smart contract threat mitigation solutions within five orthogonal dimensions: defense modality, core method, targeted contracts, input-output data mapping, and threat model. We classify 133 existing threat mitigation solutions using our taxonomy and confirm that the proposed five dimensions allow us to concisely and accurately describe any smart contract threat mitigation solution. In addition to learning what the threat mitigation solutions do, we also show how these solutions work by synthesizing their actual designs into a set of uniform workflows corresponding to the eight existing defense core methods. We further create an integrated coverage map for the known smart contract vulnerabilities by the existing threat mitigation solutions. Finally, we perform the evidence-based evolutionary analysis, in which we identify trends and future perspectives of threat mitigation in smart contracts and pinpoint major weaknesses of the existing methodologies. For the convenience of smart contract security developers, auditors, users, and researchers, we deploy and maintain a regularly updated comprehensive open-source online registry of threat mitigation solutions, called Security Threat Mitigation (STM) Registry at .},
journal = {ACM Comput. Surv.},
month = {jul},
articleno = {326},
numpages = {37},
keywords = {Smart contracts, blockchain, security}
}

@proceedings{10.1145/3561278,
title = {MISNC '22: Proceedings of the 9th Multidisciplinary International Social Networks Conference},
year = {2022},
isbn = {9781450398435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Matsuyama, Japan}
}

@inproceedings{10.1145/3457337.3457845,
author = {Tran, Canh-Tuan and Pham, Van-Duy and Nguyen, Thang and Dinh, Huu-Hai-Quan and Hoang, Minh-Tri and Dao, Thanh-Chung and Nguyen, BinhMinh and Do, Ba-Lam},
title = {A Novel Approach for Developing Decentralized Storage and Sharing Systems},
year = {2021},
isbn = {9781450384001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3457337.3457845},
doi = {10.1145/3457337.3457845},
abstract = {In recent years, the proliferation of blockchain technology has opened many research directions. In this context, the combination of blockchain-based techniques and traditional methods to improve existing systems has received significant interest from researchers. In this paper, we present a decentralized storage and sharing system based on a combination of IPFS (Inter-Planetary File System), encryption technologies (including Advanced Encryption Standard (AES), Elliptic Curve Cryptosystem (ECC), ABE (Attribute-based Encryption), Multi-Authority ABE (MA-ABE)), and multichain. In particular, we facilitate the advantages of the IPFS network to store user's data in a distributed manner. Furthermore, we make use of a cryptographer to protect the privacy of data. The hash returned by the IPFS network will be stored in our multichain architecture to provide transparency for all users participating in the system. To the best of our knowledge, it is the first storage and sharing system using IPFS, cryptographer, and multichain to ensure decentralized, trustworthy, transparent characteristics for storing and sharing data.},
booktitle = {Proceedings of the 3rd ACM International Symposium on Blockchain and Secure Critical Infrastructure},
pages = {85–90},
numpages = {6},
keywords = {IPFs, blockchain, encryption, sharing, storage},
location = {Virtual Event, Hong Kong},
series = {BSCI '21}
}

@inproceedings{10.1145/3613904.3641921,
author = {Nicholson, Rebecca and Strachan, Rebecca and Dele-Ajayi, Opeyemi and Fasae, Kemi},
title = {Emergency Remote Education in Nigeria: Challenges and Design Opportunities},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641921},
doi = {10.1145/3613904.3641921},
abstract = {There are currently approximately 20.2 million children in Nigeria out of school, exacerbated by ongoing conflicts demonstrating an ongoing need for Emergency Remote Education (ERE). Despite this, Nigeria remains an under-explored context and the specific challenges of providing ERE there are not fully understood. This paper reports on a mixed methods study of teachers experiences of enacting ERE in Nigeria in April 2020 with a questionnaire (n=374), diary study and follow up interviews (n=20) carried out. The contributions of the paper are two-fold; firstly, an in-depth study of ERE in Nigeria, demonstrating that teachers used WhatsApp as a tool of practical necessity, configured it to create a continued sense of place, and continued to enact largely traditional pedagogies. Secondly, through reflection on these findings, we offer initial design considerations for technology use in ERE in low resource settings before outlining continuing design challenges for HCI researchers in this context.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {567},
numpages = {14},
keywords = {Emergency Remote Education, Low Resource Settings, Mobile Learning, Nigeria},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@proceedings{10.1145/3592571,
title = {ICDAR '23: Proceedings of the 4th ACM Workshop on Intelligent Cross-Data Analysis and Retrieval},
year = {2023},
isbn = {9798400701863},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Thessaloniki, Greece}
}

@inproceedings{10.1145/3278293.3278305,
author = {Truong, Thinh and Dao, An and Nguyen, Long and Dinh, Dien},
title = {Improving Named Entity Recognition of English and Vietnamese Languages using Bilingual Constraints},
year = {2018},
isbn = {9781450365512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278293.3278305},
doi = {10.1145/3278293.3278305},
abstract = {Named entity recognition plays a crucial role in many Natural Language Processing tasks because the semantic information is carried by entities. The recent efforts are trying to reduce the annotation labor because the state-of-the-art Named Entity Recognition systems are still based on supervised machine learning algorithms that require huge amounts of training data. Such training data are difficult and expensive to produce manually. In particular, Vietnamese is a resource-limited language which lacks high-quality named entity annotated corpora. This limitation leads to the low performance of Vietnamese Named Entity Recognition. Therefore, in this paper, thanks to the use of an existing unannotated English-Vietnamese bilingual corpus, we propose an approach to improve Named Entity Recognition systems of both English and Vietnamese languages. Experimental results show an improvement of both English and Vietnamese Named Entity Recognition compared to the strong baseline StanfordNER. In particular, Vietnamese Named Entity Recognition improves significantly by 18.45\% in term of F1-score. As for the English side, F1-score improves from 92.44\% to 95.05\%. Our proposed method can also be generalized to apply to other resource-limited languages.},
booktitle = {Proceedings of the 2nd International Conference on Natural Language Processing and Information Retrieval},
pages = {70–75},
numpages = {6},
keywords = {Bilingual text, Named entity recognition, Word alignment},
location = {Bangkok, Thailand},
series = {NLPIR '18}
}

@inproceedings{10.1145/3034950.3034986,
author = {Dao-ping, Wang and Qing-yu, Shang and Bo-qing, Zhang},
title = {Research on the Coordination of a Dual-channel Supply Chain Considering Fairness Concern},
year = {2017},
isbn = {9781450348348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3034950.3034986},
doi = {10.1145/3034950.3034986},
abstract = {With considering the retailer' fairness concern, the coordination of a dual-channel supply chain is researched. This paper develops a model of Stackelberg game between the manufacturer and the retailer, introducing the revenue sharing contract to coordinate the dual-channel supply chain. The impact of the retailer's fairness concern on both sides of decisions is analyzed. It is concluded that, revenue sharing contract can coordinate the supply chain. Finally, the results show that the retailer's fairness concern is beneficial to improve its own utility, but it damages the profits of manufacturer.},
booktitle = {Proceedings of the 2017 International Conference on Management Engineering, Software Engineering and Service Sciences},
pages = {214–218},
numpages = {5},
keywords = {consumer utility, dual-channel supply chain, fairness concern, revenue sharing contract},
location = {Wuhan, China},
series = {ICMSS '17}
}

@inproceedings{10.1145/3302506.3312609,
author = {Cao, Nam and Saukh, Olga and Thiele, Lothar},
title = {An automated real-time and affordable airborne pollen sensing system: poster abstract},
year = {2019},
isbn = {9781450362849},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302506.3312609},
doi = {10.1145/3302506.3312609},
abstract = {In this paper, we present the design of our prototype of an automated real-time and affordable pollen sensing system. The design consists of three main subsystems: (1) a trap with automatic filtering, (2) a particle concentration system, and (3) a digital microscope with autofocus. The prototype shows effective particle gathering, filtering and concentration in a tiny sized area. As a result, we reduce particle loss and improve image quality taken by the optical system when searching and autofocusing on pollen grains. Our first prototype collects raw time-stamped data and transmits these to the backend server where we plan to run the detection and classification algorithms to extract accurate pollen counts from microscopic images. The key advantage of processing images at the backend is that we let the experts undertake corrective actions and help the system learn to detect and classify pollen using state-of-the-art interactive imitation learning algorithms. The final model can then run locally on embedded hardware.},
booktitle = {Proceedings of the 18th International Conference on Information Processing in Sensor Networks},
pages = {321–322},
numpages = {2},
location = {Montreal, Quebec, Canada},
series = {IPSN '19}
}

@inproceedings{10.1145/3461353.3461374,
author = {Gao, Zhipeng and Huang, Junmeng and Zhao, Chen},
title = {A double-phase search algorithm for sub-optimal path finding},
year = {2021},
isbn = {9781450388634},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461353.3461374},
doi = {10.1145/3461353.3461374},
abstract = {Traditional optimal path finding algorithms are usually too complex for real world problems, motivating the need to find path with sub-optimality. Typically suboptimal algorithms use a single admissible heuristic value to decide how to find a path and bound the cost. Algorithms like Weighted A*(WA*), Convex upward parabola(XUP) and Convex downward parabola(XDP) have overcome the node re-expansion problem during search. However, this re-incur a balance between the quality of path and the speed of search. In this paper, we research the process of extending and put forward an algorithm that would more efficiently operate the search while on the same time not lower the quality of path. This algorithm includes two phase of search, the first phase is to fasten the process of path finding, while the second phase is to guarantee the quality of path. In most maps we choose from Dragon Age Origins(DAO), our algorithm performs better than WA*.},
booktitle = {Proceedings of the 2021 5th International Conference on Innovation in Artificial Intelligence},
pages = {190–195},
numpages = {6},
keywords = {A*, expansion, obstacle avoidance, path finding, sub-optimal},
location = {Xia men, China},
series = {ICIAI '21}
}

@article{10.1109/TNET.2016.2639061,
author = {Dao, Tuan A. and Singh, Indrajeet and Madhyastha, Harsha V. and Krishnamurthy, Srikanth V. and Cao, Guohong and Mohapatra, Prasant},
title = {TIDE: A User-Centric Tool for Identifying Energy Hungry Applications on Smartphones},
year = {2017},
issue_date = {June 2017},
publisher = {IEEE Press},
volume = {25},
number = {3},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2016.2639061},
doi = {10.1109/TNET.2016.2639061},
abstract = {Today, many smartphone users are unaware of what applications apps they should stop using to prevent their battery from running out quickly. The problem is identifying such apps is hard due to the fact that there exist hundreds of thousands of apps and their impact on the battery is not well understood. We show via extensive measurement studies that the impact of an app on battery consumption depends on both environmental wireless factors and usage patterns. Based on this, we argue that there exists a critical need for a tool that allows a user to: 1 identify apps that are energy hungry and 2 understand why an app is consuming energy, on her phone. Toward addressing this need, we present TIDE, a tool to detect high energy apps on any particular smartphone. TIDE’s key characteristic is that it accounts for usage-centric information while identifying energy hungry apps from among a multitude of apps that run simultaneously on a user’s phone. Our evaluation of TIDE on a test bed of Android-based smartphones, using week-long smartphone usage traces from 17 real users, shows that TIDE correctly identifies over 94\% of energy-hungry apps and has a false positive rate of &lt; 6\%.},
journal = {IEEE/ACM Trans. Netw.},
month = {jun},
pages = {1459–1474},
numpages = {16}
}

@inproceedings{10.1145/1228784.1228797,
author = {Das, Debasish and Shebaita, Ahmed and Ismail, Yehea and Zhou, Hai and Killpack, Kip},
title = {NostraXtalk: a predictive framework for accurate static timing analysis in udsm vlsi circuits},
year = {2007},
isbn = {9781595936059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1228784.1228797},
doi = {10.1145/1228784.1228797},
abstract = {This paper presents a predictive framework for accurate static timing analysis in UDSM VLSI circuits. As technology scales to smaller dimensions, coupling capacitances are becoming a critical factor in signal integrity analysis. Coupling capacitances contribute to the noise and play a seminalrole in determining the timing windows of a circuit. Accuratean alysis of coupling effects is indispensable for meaning fulstatic timing and signal integrity analysis. Our proposed framework presents a Directed Search technique to calculate accurate coupling effects. We performed experiments on theISCAS'85 benchmarks and present the accuracy improvement up-to 45.5\% compared to existing approaches. We also show that our framework decreased cell delay look-uptable accesses up-to 64.8\%. Our results present the coupling effect on static timing analysis.},
booktitle = {Proceedings of the 17th ACM Great Lakes Symposium on VLSI},
pages = {25–30},
numpages = {6},
keywords = {crosstalk, modeling, static timing analysis},
location = {Stresa-Lago Maggiore, Italy},
series = {GLSVLSI '07}
}

@proceedings{10.1145/3611643,
title = {ESEC/FSE 2023: Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to ESEC/FSE 2023, the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ESEC/FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. ESEC/FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {San Francisco, CA, USA}
}

@proceedings{10.1145/3625078,
title = {BIOTC '23: Proceedings of the 2023 5th Blockchain and Internet of Things Conference},
year = {2023},
isbn = {9798400708213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Osaka, Japan}
}

@article{10.1145/3548686,
author = {Mishra, Alekha Kumar and Singh, Osho and Kumar, Abhay and Puthal, Deepak and Sharma, Pradip Kumar and Pradhan, Biswajeet},
title = {Hybrid Mode of Operation Schemes for P2P Communication to Analyze End-Point Individual Behaviour in IoT},
year = {2022},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1550-4859},
url = {https://doi.org/10.1145/3548686},
doi = {10.1145/3548686},
abstract = {The Internet of Behavior is the recent trend in the Internet of Things (IoT), which analyzes the behaviour of individuals using huge amounts of data collected from their activities. The behavioural data collection process from an individual to a data center in the network layer of the IoT is addressed by the Routing Protocol for Low-powered Lossy Networks (RPL) downward routing policy. A hybrid mode of operation in RPL is designed to minimize the limitations of standard modes of operations in the downward routing of RPL. The existing hybrid modes use the common parameters, such as routing table capacity, energy level, and hop-count for making storing mode decisions at each node. However, none of these works have utilized the deciding parameters, such as number of Destination-Oriented Directed Acyclic Graph (DODAG) children, rank, and transmission traffic density for this purpose. In this article, we propose two hybrid MOPs for RPL focusing on the aspect of efficient downward communication for the Internet of Behaviors. The first version decides the mode of each node based on the rank and number of DODAG children of the node. In addition, the proposed Mode of Operation (MOP) has the provision to balance the task of a storing node that is currently running on low power and computational resources by a handover mechanism among the ancestors. The second version of the hybrid MOP utilizes the upward and downward transmission traffic probabilities together with 170 rule or 1D cellular automata to decide the operating mode of a node. The analysis on the upper bound on communication shows that both proposed works have communication overhead nearly equal to the storing mode. The experimental results also infer that the proposed adaptive MOP have lower communication overhead compared with standard storing modes and existing schemes ARPL, MERPL, and HIMOPD.},
journal = {ACM Trans. Sen. Netw.},
month = {dec},
articleno = {31},
numpages = {23},
keywords = {IoT, IoB, RPL, downward routing, MOP, storing, non-storing, hybrid MOP, rank, downward transmission traffic}
}

@proceedings{10.1145/3500868,
title = {CSCW'22 Companion: Companion Publication of the 2022 Conference on Computer Supported Cooperative Work and Social Computing},
year = {2022},
isbn = {9781450391900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Taiwan}
}

@inproceedings{10.1145/3011077.3011117,
author = {Le, Duc-Hau and Nguyen, Dai-Phong and Dao, Anh-Minh},
title = {Significant path selection improves the prediction of novel drug-target interactions},
year = {2016},
isbn = {9781450348157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3011077.3011117},
doi = {10.1145/3011077.3011117},
abstract = {Identifying the interactions between drugs and targets is a crucial step in the process of discovering new drugs. There has been a number of computational methods proposed for the problem. Among them, machine learning-based methods usually utilizes the similarity between drugs and between targets to build kernel matrices, which are used to predict novel drug-target interactions with classification models. While network-based methods usually formulate the prediction as a ranking problem where candidate targets are according to a drug of interest and/or its known targets. A common disadvantage of the network-based methods is that they mainly look for novel targets which are close to known targets in the network. In this study, we proposed a method, namely SigTarget, to overcome this limitation. More specifically, SigTarget ranks candidate targets based on a probability with which they connect to known targets by choosing significant links between known and candidate targets. This method was adapted from an algorithm calculating relative importance between nodes in a network. Simulation results show that SigTarget was better than some existing methods such as TBSI, DBSI and RWR for a set of drugs collected from KEGG database. In addition, we showed the ability of SigTarget in predicting novel drug targets by showing that highly ranked candidate targets obtained from SigTarget are also verified in another drug database, DrugBank.},
booktitle = {Proceedings of the 7th Symposium on Information and Communication Technology},
pages = {30–35},
numpages = {6},
keywords = {drug-target prediction, network-based ranking method, random walk with restart, significant path, systems pharmacology},
location = {Ho Chi Minh City, Vietnam},
series = {SoICT '16}
}

@article{10.1145/3391195,
author = {Chen, Huashan and Pendleton, Marcus and Njilla, Laurent and Xu, Shouhuai},
title = {A Survey on Ethereum Systems Security: Vulnerabilities, Attacks, and Defenses},
year = {2020},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3391195},
doi = {10.1145/3391195},
abstract = {Blockchain technology is believed by many to be a game changer in many application domains. While the first generation of blockchain technology (i.e., Blockchain 1.0) is almost exclusively used for cryptocurrency, the second generation (i.e., Blockchain 2.0), as represented by Ethereum, is an open and decentralized platform enabling a new paradigm of computing—Decentralized Applications (DApps) running on top of blockchains. The rich applications and semantics of DApps inevitably introduce many security vulnerabilities, which have no counterparts in pure cryptocurrency systems like Bitcoin. Since Ethereum is a new, yet complex, system, it is imperative to have a systematic and comprehensive understanding on its security from a holistic perspective, which was previously unavailable in the literature. To the best of our knowledge, the present survey, which can also be used as a tutorial, fills this void. We systematize three aspects of Ethereum systems security: vulnerabilities, attacks, and defenses. We draw insights into vulnerability root causes, attack consequences, and defense capabilities, which shed light on future research directions.},
journal = {ACM Comput. Surv.},
month = {jun},
articleno = {67},
numpages = {43},
keywords = {Blockchain, Ethereum, security, smart contract}
}

@proceedings{10.1145/3564665,
title = {ICBDR '22: Proceedings of the 6th International Conference on Big Data Research},
year = {2022},
isbn = {9781450396776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Harbin, China}
}

@inproceedings{10.1145/2676585.2676610,
author = {Nguyen, Binh Minh and Dao, Quang Minh},
title = {Towards a semantic model of resource in cloud environment},
year = {2014},
isbn = {9781450329309},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2676585.2676610},
doi = {10.1145/2676585.2676610},
abstract = {Cloud computing has become fundamental technologies for most of IT-services today. This is due to primarily to its elastic nature: users or customers can acquire and release resources on-demand, and pay only for the resources they need (pay-per-use or pay-as-you-go model). Although the number and quality of cloud services are daily rising, but on the other aspect, the user requirements for the services also increase very fast and diversely. One of the prominent user demands is the need of a solution that can help them automatically choose suitable resources to deploy appliances into cloud environment. Based on the previous work presented in [1], in this paper, we go further to develop a primitive semantic model of cloud resources derived from multi-infrastructures. This semantic model allows users to create service and automatically deploy them to suitable cloud according to specific requirements of each. In this way, the approach enables appliance interoperability and elasticity among clouds. Our solution thus achieves value-added feature for cloud providers and simultaneously lowers barriers for users when using cloud computing.},
booktitle = {Proceedings of the 5th Symposium on Information and Communication Technology},
pages = {271–279},
numpages = {9},
keywords = {abstraction, cloud computing, elasticity, interoperability, semantic cloud, service deployment, service development},
location = {Hanoi, Viet Nam},
series = {SoICT '14}
}

@article{10.1145/3464421,
author = {Tolmach, Palina and Li, Yi and Lin, Shang-Wei and Liu, Yang and Li, Zengxiang},
title = {A Survey of Smart Contract Formal Specification and Verification},
year = {2021},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {7},
issn = {0360-0300},
url = {https://doi.org/10.1145/3464421},
doi = {10.1145/3464421},
abstract = {A smart contract is a computer program that allows users to automate their actions on the blockchain platform. Given the significance of smart contracts in supporting important activities across industry sectors including supply chain, finance, legal, and medical services, there is a strong demand for verification and validation techniques. Yet, the vast majority of smart contracts lack any kind of formal specification, which is essential for establishing their correctness. In this survey, we investigate formal models and specifications of smart contracts presented in the literature and present a systematic overview to understand the common trends. We also discuss the current approaches used in verifying such property specifications and identify gaps with the hope to recognize promising directions for future work.},
journal = {ACM Comput. Surv.},
month = {jul},
articleno = {148},
numpages = {38},
keywords = {Smart contract, formal specification, formal verification, properties}
}

@article{10.1145/3649132,
author = {Keizer, Navin and Ascigil, Onur and Kr\'{o}l, Michal and Kutscher, Dirk and Pavlou, George},
title = {A Survey on Content Retrieval on the Decentralised Web},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {8},
issn = {0360-0300},
url = {https://doi.org/10.1145/3649132},
doi = {10.1145/3649132},
abstract = {The control, governance, and management of the web have become increasingly centralised, resulting in security, privacy, and censorship concerns. Decentralised initiatives have emerged to address these issues, beginning with decentralised file systems. These systems have gained popularity, with major platforms serving millions of content requests daily. Complementing the file systems are decentralised search engines and name-registry infrastructures, together forming the basis of a decentralised web. This survey article analyses research trends and emerging technologies for content retrieval on the decentralised web, encompassing both academic literature and industrial projects.Several challenges hinder the realisation of a fully decentralised web. Achieving comparable performance to centralised systems without compromising decentralisation is a key challenge. Hybrid infrastructures, blending centralised components with verifiability mechanisms, show promise to improve decentralised initiatives. While decentralised file systems have seen more mature deployments, they still face challenges such as usability, performance, privacy, and content moderation. Integrating these systems with decentralised name-registries offers a potential for improved usability with human-readable and persistent names for content. Further research is needed to address security concerns in decentralised name-registries and enhance governance and crypto-economic incentive mechanisms.},
journal = {ACM Comput. Surv.},
month = {apr},
articleno = {198},
numpages = {39},
keywords = {Decentralised web, Peer-to-Peer, content addressing, blockchain, web3.01}
}

@inproceedings{10.1145/3661167.3661290,
author = {De Luca, Marco and Di Meglio, Sergio and Fasolino, Anna Rita and Starace, Luigi Libero Lucio and Tramontana, Porfirio},
title = {Automatic Assessment of Architectural Anti-patterns and Code Smells in Student Software Projects},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661290},
doi = {10.1145/3661167.3661290},
abstract = {When teaching Programming and Software Engineering in Bachelor’s Degree programs, the emphasis on creating functional software projects often overshadows the focus on software quality, a trend consistent with ACM curricula recommendations. Dedicated Software Engineering courses take typically place in the later stages of the curriculum, and allocate only limited time to software quality, leaving educators with the difficult task of deciding which quality aspects to prioritize. To educate students on the importance of developing high-quality code, it is important to introduce these skills as part of the assessment criteria. To this end, we have implemented a pipeline based on advanced frameworks such as ArchUnit and SonarQube. It was successfully tested on a class of students engaged in the Object Oriented Programming course, demonstrating its usefulness as a resource for educators and providing some concrete evidence of quality problems in student projects.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {565–569},
numpages = {5},
keywords = {architectural anti-patterns, code quality, oop courses, quality criteria},
location = {Salerno, Italy},
series = {EASE '24}
}

@article{10.1145/3641289,
author = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and Ye, Wei and Zhang, Yue and Chang, Yi and Yu, Philip S. and Yang, Qiang and Xie, Xing},
title = {A Survey on Evaluation of Large Language Models},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/3641289},
doi = {10.1145/3641289},
abstract = {Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas. Secondly, we answer the ‘where’ and ‘how’ questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at:},
journal = {ACM Trans. Intell. Syst. Technol.},
month = {mar},
articleno = {39},
numpages = {45},
keywords = {Large language models, evaluation, model assessment, benchmark}
}

@article{10.14778/3342263.3342637,
author = {Jia, Ruoxi and Dao, David and Wang, Boxin and Hubis, Frances Ann and Gurel, Nezihe Merve and Li, Bo and Zhang, Ce and Spanos, Costas and Song, Dawn},
title = {Efficient task-specific data valuation for nearest neighbor algorithms},
year = {2019},
issue_date = {July 2019},
publisher = {VLDB Endowment},
volume = {12},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3342263.3342637},
doi = {10.14778/3342263.3342637},
abstract = {Given a data set D containing millions of data points and a data consumer who is willing to pay for $X to train a machine learning (ML) model over D, how should we distribute this $X to each data point to reflect its "value"? In this paper, we define the "relative value of data" via the Shapley value, as it uniquely possesses properties with appealing real-world interpretations, such as fairness, rationality and decentralizability. For general, bounded utility functions, the Shapley value is known to be challenging to compute: to get Shapley values for all N data points, it requires O(2N) model evaluations for exact computation and O(N log N) for (ϵ, δ)-approximation.In this paper, we focus on one popular family of ML models relying on K-nearest neighbors (KNN). The most surprising result is that for unweighted KNN classifiers and regressors, the Shapley value of all N data points can be computed, exactly, in O(N log N) time - an exponential improvement on computational complexity! Moreover, for (ϵ, δ)-approximation, we are able to develop an algorithm based on Locality Sensitive Hashing (LSH) with only sublinear complexity O(Nh(ϵ, K) log N) when ϵ is not too small and K is not too large. We empirically evaluate our algorithms on up to 10 million data points and even our exact algorithm is up to three orders of magnitude faster than the baseline approximation algorithm. The LSH-based approximation algorithm can accelerate the value calculation process even further.We then extend our algorithm to other scenarios such as (1) weighed KNN classifiers, (2) different data points are clustered by different data curators, and (3) there are data analysts providing computation who also requires proper valuation. Some of these extensions, although also being improved exponentially, are less practical for exact computation (e.g., O(NK) complexity for weigthed KNN). We thus propose an Monte Carlo approximation algorithm, which is O(N(log N)2/(log K)2) times more efficient than the baseline approximation algorithm.},
journal = {Proc. VLDB Endow.},
month = {jul},
pages = {1610–1623},
numpages = {14}
}

@proceedings{10.1145/3655038,
title = {HotStorage '24: Proceedings of the 16th ACM Workshop on Hot Topics in Storage and File Systems},
year = {2024},
isbn = {9798400706301},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santa Clara, CA, USA}
}

@inproceedings{10.1145/3437992.3439934,
author = {Annenkov, Danil and Milo, Mikkel and Nielsen, Jakob Botsch and Spitters, Bas},
title = {Extracting smart contracts tested and verified in Coq},
year = {2021},
isbn = {9781450382991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437992.3439934},
doi = {10.1145/3437992.3439934},
abstract = {We implement extraction of Coq programs to functional languages based on MetaCoq's certified erasure. As part of this, we implement an optimisation pass removing unused arguments. We prove the pass correct wrt. a conventional call-by-value operational semantics of functional languages. We apply this to two functional smart contract languages, Liquidity and Midlang, and to the functional language Elm.  Our development is done in the context of the ConCert framework that enables smart contract verification. We contribute a verified boardroom voting smart contract featuring maximum voter privacy such that each vote is kept private except under collusion of all other parties.  We also integrate property-based testing into ConCert using QuickChick and our development is the first to support testing properties of interacting smart contracts. We test several complex contracts such as a DAO-like contract, an escrow contract, an implementation of a Decentralized Finance (DeFi) contract which includes a custom token standard (Tezos FA2), and more.  In total, this gives us a way to write dependent programs in Coq, test them semi-automatically, verify, and then extract to functional smart contract languages, while retaining a small trusted computing base of only MetaCoq and the pretty-printers into these languages.},
booktitle = {Proceedings of the 10th ACM SIGPLAN International Conference on Certified Programs and Proofs},
pages = {105–121},
numpages = {17},
keywords = {Coq, blockchain, certified programming, code extraction, formal verification, proof assistants, property-based testing, smart contracts, software correctness},
location = {Virtual, Denmark},
series = {CPP 2021}
}

@inproceedings{10.1145/2072298.2072045,
author = {Dao, Minh-Son and Dang-Nguyen, Duc-Tien and De Natale, Francesco G.B.},
title = {Signature-image-based event analysis for personal photo albums},
year = {2011},
isbn = {9781450306164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2072298.2072045},
doi = {10.1145/2072298.2072045},
abstract = {Quick reorganizing and draft annotating personal photo albums under event scheme is an emerging trend. In this research, a method has been developed to meet such requirements using the idea of gist and mosaic art so that viewers could understand the meaning of a whole scene without paying much attention in individual details. First, given a photo album, all chronologically ordered images are normalized to a smaller size, and then mosaicked side-by-side to create a signature image representing for that album. Next, by integrating the optimized linear programming with the color descriptor of the signature image, not only the event-type of the album but also all sub-event-types of the sub-sequence photos are decided. More than 19,000 images of five varied event-types have been used to evaluate the proposed method. Experimental results show that the proposed method could detect events towards annotation and re-organization of personal photo albums with high accuracy at a rapid speed.},
booktitle = {Proceedings of the 19th ACM International Conference on Multimedia},
pages = {1481–1484},
numpages = {4},
keywords = {event analysis, gist, mosaic art, optimization linear programming, personal photo album, signature image base},
location = {Scottsdale, Arizona, USA},
series = {MM '11}
}

@inproceedings{10.1145/3185768.3186303,
author = {Portillo-Dominguez, A. Omar},
title = {Towards an Efficient Benchmark Generation Engine for Garbage Collection},
year = {2018},
isbn = {9781450356299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3185768.3186303},
doi = {10.1145/3185768.3186303},
abstract = {Garbage Collection (GC) is a key feature of many modern programming technologies. It offers significant software engineering benefits over explicitly memory management. Nonetheless, it is also a major cause of performance degradation. As the rate of adoption of GC-related technologies continues to grow, it is highly relevant to understand its performance impact. However, this is challenging due to the non-deterministic nature of GC. To tackle this problem, we present an engine (HERMES) to create realistic GC benchmarks by effectively capturing the GC/memory behaviours exhibited by real-world Java applications. Our experiments prove how HERMES can be useful to strengthen the evaluation of GC-related advancements. This is achieved by broadening the number and diversity of the test scenarios, as well as reducing the time invested in testing.},
booktitle = {Companion of the 2018 ACM/SPEC International Conference on Performance Engineering},
pages = {9–12},
numpages = {4},
keywords = {Java, benchmark generation, garbage collection, object-oriented systems},
location = {Berlin, Germany},
series = {ICPE '18}
}

@article{10.1145/3626315,
author = {Huawei, Huang and Qinnan, Zhang and Taotao, Li and Qinglin, Yang and Zhaokang, Yin and Junhao, Wu and Xiong, Zehui and Jianming, Zhu and Wu, Jiajing and Zheng, Zibin},
title = {Economic Systems in the Metaverse: Basics, State of the Art, and Challenges},
year = {2023},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3626315},
doi = {10.1145/3626315},
abstract = {Economic systems play pivotal roles in the metaverse. However, we have not yet found an overview that systematically introduces economic systems for the metaverse. Therefore, we review the state-of-the-art solutions, architectures, and systems related to economic systems. When investigating those state-of-the-art studies, we keep two questions in mind: (1) What is the framework of economic systems in the context of the metaverse? and (2) What activities would economic systems engage in the metaverse? This article aims to disclose insights into the economic systems that work for both the current and the future metaverse. To have a clear overview of the economic system framework, we mainly discuss the connections among three fundamental elements in the metaverse, i.e., digital creation, digital assets, and the digital trading market. After that, we elaborate on each topic of the proposed economic system framework. Those topics include incentive mechanisms, monetary systems, digital wallets, decentralized finance activities, and cross-platform interoperability for the metaverse. For each topic, we mainly discuss three questions: (a) the rationale of this topic, (b) why the metaverse needs this topic, and (c) how this topic will evolve in the metaverse. Through this overview, we wish readers can better understand what economic systems the metaverse needs and the insights behind the economic activities in the metaverse.},
journal = {ACM Comput. Surv.},
month = {nov},
articleno = {99},
numpages = {33},
keywords = {Metaverse, economic system, cryptocurrency, non-fungible tokens, blockchain, incentive mechanism, cross-metaverse interoperability, decentralized finance}
}

@proceedings{10.1145/3659211,
title = {BDEIM '23: Proceedings of the 2023 4th International Conference on Big Data Economy and Information Management},
year = {2023},
isbn = {9798400716669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Zhengzhou, China}
}

@proceedings{10.1145/3650215,
title = {ICMLCA '23: Proceedings of the 2023 4th International Conference on Machine Learning and Computer Application},
year = {2023},
isbn = {9798400709449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hangzhou, China}
}

@inproceedings{10.1145/2461466.2461494,
author = {Dao, Minh-Son and Boato, Giulia and De Natale, Francesco G.B. and Nguyen, Truc-Vien},
title = {Jointly exploiting visual and non-visual information for event-related social media retrieval},
year = {2013},
isbn = {9781450320337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2461466.2461494},
doi = {10.1145/2461466.2461494},
abstract = {In this contribution, we propose a watershed-based method with support from external data sources and visual information to detect social events in web multimedia. The idea is based on two main observations: (1) people cannot be involved in more than one event at the same time, and (2) people tend to introduce similar annotations for all images associated to the same event. Based on these observations, the metadata is turned to an image so that each row contains all records belonging to one user; and these records are sorted by time. Thus, the social event detection is turned to watershed-based image segmentation, where Markers are generated by using (keyword, location, visual) features with support of external data sources, and the Flood progress is carried on by taking into account (tags set, time, visual) features. We test our algorithm on the MediaEval 2012 dataset both using only external data but also introducing visual information.},
booktitle = {Proceedings of the 3rd ACM Conference on International Conference on Multimedia Retrieval},
pages = {159–166},
numpages = {8},
keywords = {relatedness, social event detection, watershed},
location = {Dallas, Texas, USA},
series = {ICMR '13}
}

@article{10.1145/3645087,
author = {Shahidinejad, Ali and Abawajy, Jemal},
title = {An All-Inclusive Taxonomy and Critical Review of Blockchain-Assisted Authentication and Session Key Generation Protocols for IoT},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {7},
issn = {0360-0300},
url = {https://doi.org/10.1145/3645087},
doi = {10.1145/3645087},
abstract = {Authentication and Session Key Generation Protocols (SKGPs) play an essential role in securing the communication channels of connected Internet of Things (IoT) devices. Recently, through blockchain integration, scholars have tried to enhance the security and applicability of SKGPs. In brief, blockchain is a distributed ledger technology that can provide interesting features such as immutability, transparency, and accountability without any need for the active participation of trusted parties. This survey presents a comprehensive critical review of blockchain-assisted authentication and SKGPs, suggested for different IoT domains, including Internet of Vehicles, Internet of Drones, and Industrial IoT. Our survey categorizes existing schemes based on several criteria, including IoT application domains, security aspects, and blockchain components. By presenting an unbiased critical review and taxonomy of protocols, we aim to clarify the key challenges. Our review will specifically indicate what properties authors gained or lost through the integration of blockchain. To our best knowledge, this survey is the only one that offers all prerequisites for interested readers in blockchain-integrated SKGPs, such as security features and attacks, attack models, verification tools, blockchain types, blockchain platforms, and consensus mechanisms. Further, our survey elaborates existing research gaps in blockchain-assisted SKGPs. In doing so, we aim to guide future research in this field and provide researchers with the essential information they require.},
journal = {ACM Comput. Surv.},
month = {apr},
articleno = {186},
numpages = {38},
keywords = {Authentication, blockchain, Internet of Things (IoT), session key generation protocol (SKGP)}
}

@inproceedings{10.1145/3582515.3609556,
author = {Daliparthi, Venkata Satya Sai Ajay and Momen, Nurul and Tutschku, Kurt and De Prado, Miguel},
title = {ViSDM 1.0: Vision Sovereignty Data Marketplace a Decentralized Platform for Crowdsourcing Data Collection and Trading},
year = {2023},
isbn = {9798400701160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582515.3609556},
doi = {10.1145/3582515.3609556},
abstract = {The demand for large-scale diverse datasets is rapidly increasing due to the advancements in AI services impacting day-to-day life. However, gathering such massive datasets still remains a critical challenge in the AI service engineering pipeline, especially in the computer vision domain where labeled data is scarce. Rather than isolated data collection, crowdsourcing techniques have shown promising potential to achieve the data collection task in a time and cost-efficient manner. In the existing crowdsourcing marketplaces, the crowd works to fulfill consumer-defined requirements where in the end consumer gains the data ownership and the crowd is compensated with task-based payment. On the contrary, this work proposes a blockchain-based decentralized marketplace named Vision Sovereignty Data Marketplace (ViSDM), in which the crowd works to fulfill global requirements \&amp; holds data ownership, the consumers pay a certain data price to perform a computing task (model training/testing), the data price is distributed among the crowd in a one-to-many manner through smart contracts, thus allowing the crowd to gain profit from each consumer transaction occurring on their data. The marketplace is implemented as multiple smart contracts and is evaluated based on blockchain-transaction gas fees for the stakeholder interaction \&amp; by running scenarios-based simulations. Furthermore, discussions address the challenges included in maintaining data quality and the future milestones towards deployment.},
booktitle = {Proceedings of the 2023 ACM Conference on Information Technology for Social Good},
pages = {374–383},
numpages = {10},
keywords = {Blockchain, Computer Vision, Crowdsourcing, Data Marketplaces, Smart Contracts},
location = {Lisbon, Portugal},
series = {GoodIT '23}
}

@article{10.1145/3505263,
author = {Wu, Siwei and Wu, Lei and Zhou, Yajin and Li, Runhuai and Wang, Zhi and Luo, Xiapu and Wang, Cong and Ren, Kui},
title = {Time-travel Investigation: Toward Building a Scalable Attack Detection Framework on Ethereum},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3505263},
doi = {10.1145/3505263},
abstract = {Ethereum has been attracting lots of attacks, hence there is a pressing need to perform timely investigation and detect more attack instances. However, existing systems suffer from the scalability issue due to the following reasons. First, the tight coupling between malicious contract detection and blockchain data importing makes them infeasible to repeatedly detect different attacks. Second, the coarse-grained archive data makes them inefficient to replay transactions. Third, the separation between malicious contract detection and runtime state recovery consumes lots of storage.In this article, we propose a scalable attack detection framework named EthScope, which overcomes the scalability issue by neatly re-organizing the Ethereum state and efficiently locating suspicious transactions. It leverages the fine-grained state to support the replay of arbitrary transactions and proposes a well-designed schema to optimize the storage consumption. The performance evaluation shows that EthScope can solve the scalability issue, i.e., efficiently performing a large-scale analysis on billions of transactions, and a speedup of around  ( text{2,300}times )  when replaying transactions. It also has lower storage consumption compared with existing systems. Further analysis shows that EthScope can help analysts understand attack behaviors and detect more attack instances.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {apr},
articleno = {54},
numpages = {33},
keywords = {Ethereum, attack detection, vulnerability}
}

@article{10.1145/3596224,
author = {Fathalla, Efat and Wang, Chonggang and Li, Xu and Gazda, Robert and Wu, Hongyi},
title = {Redactable Distributed Ledgers: A Survey},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3596224},
doi = {10.1145/3596224},
abstract = {Blockchain and distributed ledger technology started as a decentralized infrastructure to enable and manage digital currency like Bitcoin without relying on a central authority. One of the attractive features provided by blockchain technology is its append-only “immutability” feature, which means the stored data cannot be modified or manipulated by any means once it is validated in the blockchain ledger. Such immutability helps traceability, auditing, and non-repudiation, which builds decentralized trust among un-trusted parties. Despite that, immutability if misused could lead to the permanent existence of sensitive information and misinformation in the blockchain. Incidents like broadcasting illegal content have already taken their place in blockchain systems. Such incidents call for prompt solutions for mitigation. One emerging research theme, “redactable distributed ledgers” such as redactable blockchain provides approaches for modifying ledgers with certain controllability. This article aims to survey the current research landscape about redactable distributed ledgers. We will first describe the motivations behind redactable distributed ledgers. Compared to other relevant surveys, we comprehensively summarized and briefly explained the underlying technologies for supporting redactable distributed ledgers. We mainly focused on chameleon hash-based redactable blockchain structure and classifications, with detailed comparisons and illustrations. Further, we tackled new distributed ledger structures, including the new state-of-the-art block matrix structure. Furthermore, new applications that can be enabled by redactable distributed ledgers and future research directions are discussed in detail. This article emphasizes the motivation of utilizing the redactable distributed ledgers in several critical applications to mitigate misuse of immutability features threatening the original known design of distributed ledgers.},
journal = {Distrib. Ledger Technol.},
month = {sep},
articleno = {24},
numpages = {26},
keywords = {Distributed ledgers, blockchain, redactable blockchain, chameleon hash}
}

@article{10.1145/3520441,
author = {Shudrenko, Yevhenii and Pl\"{o}ger, Daniel and Kuladinithi, Koojana and Timm-Giel, Andreas},
title = {A Novel Approach to Enhance the End-to-End Quality of Service for Avionic Wireless Sensor Networks},
year = {2022},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {4},
issn = {1533-5399},
url = {https://doi.org/10.1145/3520441},
doi = {10.1145/3520441},
abstract = {Going wireless is one of the key industrial trends, which assists the emergence of new manufacturing and maintenance processes by reducing the complexity and cost of physical equipment. However, the adoption of Wireless Sensor Networks (WSNs) in production environments is limited due to the strict Quality of Service (QoS) requirements of industrial applications. In particular, Wireless Avionics Intra-Communication (WAIC) systems operating in 4.3 GHz band are designed for intra-aircraft use cases with considerable restrictions on the transmission power of sensors, which results in multi-hop topologies, complicating a guaranteed QoS. The Internet Engineering Task Force (IETF) has developed the protocol stack IPv6 over the Time Slotted Channel Hopping (TSCH) mode of IEEE 802.15.4 (6TiSCH) based on the IEEE 802.15.4 Standard for Low-Rate Wireless Networks, which combines the TSCH reliability with ubiquitous IPv6 connectivity and with the robust Routing Protocol for Low-Power and Lossy Networks (RPL). The Scheduling Function (SF) is a core IPv6 over the TSCH mode of IEEE 802.15.4 (6TiSCH) component, but the specification of the SF is an open research topic: numerous scientific articles investigated how QoS for a wide range of applications can be met by developing specialized SFs. However, no full-scale information exchange between the layers of the 6TiSCH stack was considered to optimize the SFs and to improve the network performance. In this work, we propose a novel solution named 6TiSCH-CLX to satisfy demanding QoS requirements using cross-layer communication. It is an extension of the 6TiSCH framework at the network and Medium Access Control (MAC) layers, addressing latency and reliability challenges agnostic of the physical layer. 6TiSCH-CLX is evaluated both analytically and in simulations for several safety-critical avionic intra-communication use cases in WAIC. Preliminary results indicate considerable improvements to latency, while maintaining almost 100\% Packet Delivery Ratio (PDR) without retransmissions and they highlight the capability of the cross-layer approach compared to existing solutions.},
journal = {ACM Trans. Internet Technol.},
month = {nov},
articleno = {95},
numpages = {29},
keywords = {WAIC, 6TiSCH, MSF, WSN, IEEE 802.15.4, TSCH, IPv6, RPL, scheduling function, end-to-end QoS, avionics}
}

@article{10.1145/3659575,
author = {Halvorsen, James and Izurieta, Clemente and Cai, Haipeng and Gebremedhin, Assefaw},
title = {Applying Generative Machine Learning to Intrusion Detection: A Systematic Mapping Study and Review},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {10},
issn = {0360-0300},
url = {https://doi.org/10.1145/3659575},
doi = {10.1145/3659575},
abstract = {Intrusion Detection Systems (IDSs) are an essential element of modern cyber defense, alerting users to when and where cyber-attacks occur. Machine learning can enable IDSs to further distinguish between benign and malicious behaviors, but it comes with several challenges, including lack of quality training data and high false-positive rates. Generative Machine Learning Models (GMLMs) can help overcome these challenges. This article offers an in-depth exploration of GMLMs’ application to intrusion detection. It gives (1) a systematic mapping study of research at the intersection of GMLMs and IDSs, and (2) a detailed review providing insights and directions for future research.},
journal = {ACM Comput. Surv.},
month = {jun},
articleno = {257},
numpages = {33},
keywords = {Generative Models, Penetration Testing, Unbalanced Datasets, Cyber Alert Generation, Flow Generation, Evaluation Metrics}
}

@inproceedings{10.1145/1631272.1631377,
author = {Dao, Minh-Son and Sharma, Ishan Nath and Babaguchi, Noboru},
title = {Preserving topological information in sub-trajectories-based representation for spatio-temporal trajectories indexing and retrieval},
year = {2009},
isbn = {9781605586083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1631272.1631377},
doi = {10.1145/1631272.1631377},
abstract = {Trajectories of moving objects are known as one of the most important cues for understanding semantics in video data. Although there are a lot of significant researches dealing with trajectory analysis tailored to indexing and retrieval, several problems still remain. One of them is a trade-off between whole trajectory- and sub-trajectories- based methods. The former problem is that representing a trajectory as a whole is not appropriate for detecting similar patterns of the trajectory. In contrast, the latter is that even though some key portion of two trajectories share similar patterns, the whole trajectories may be totally different. Therefore, this paper proposes a novel method to optimize such trade-off. By representing a trajectory as a combination of sequence of "word" - each word's character represents one distinct feature extracted from sub-trajectories (i.e. segments), and a topological graph of trajectory's segments, the proposed method is shift and scale invariant, can handle occlusion and distortion, and can discover similar patterns among trajectories. Thorough comparisons with well-known methods demonstrate the superiority of the proposed method in terms of precision recall ratios.},
booktitle = {Proceedings of the 17th ACM International Conference on Multimedia},
pages = {641–644},
numpages = {4},
keywords = {PCA, spectral clustering, topological graph, trajectory, trajectory segmentation},
location = {Beijing, China},
series = {MM '09}
}

@article{10.1145/3503462,
author = {Murray-Rust, Dave and Elsden, Chris and Nissen, Bettina and Tallyn, Ella and Pschetz, Larissa and Speed, Chris},
title = {Blockchain and Beyond: Understanding Blockchains Through Prototypes and Public Engagement},
year = {2023},
issue_date = {October 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {5},
issn = {1073-0516},
url = {https://doi.org/10.1145/3503462},
doi = {10.1145/3503462},
abstract = {This article presents an annotated portfolio of projects that seek to understand and communicate the social and societal implications of blockchains, DLTs and smart contracts. These complex technologies rely on human and technical factors to deliver cryptocurrencies, shared computation and trustless protocols but have a secondary benefit in providing a moment to re-think many aspects of society, and imagine alternative possibilities. The projects use design and HCI methods to relate blockchains to a range of topics, including global supply chains, delivery infrastructure, smart grids, volunteering and charitable giving, through engaging public, exploring ideas and speculating on possible futures. Based on an extensive annotated portfolio we draw out learning for the design of blockchain systems, broadening participation and surfacing questions around imaginaries, social implications and engagement with new technology. This paints a comprehensive picture of how HCI and design can shape understandings of the future of complex technologies.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = {jan},
articleno = {41},
numpages = {73},
keywords = {Blockchains, public engagement, research through design, HCI, smart contracts, distributed ledger technology, conditional giving, distributed energy}
}

@proceedings{10.1145/3637494,
title = {CECCT '23: Proceedings of the 2023 International Conference on Electronics, Computers and Communication Technology},
year = {2023},
isbn = {9798400716300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guilin, China}
}

@proceedings{10.1145/3671016,
title = {Internetware '24: Proceedings of the 15th Asia-Pacific Symposium on Internetware},
year = {2024},
isbn = {9798400707056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macau, China}
}

